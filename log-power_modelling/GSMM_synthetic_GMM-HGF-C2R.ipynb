{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSMM mixture modelling with synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the following processing blocks:\n",
    "- Gaussian mixture model\n",
    "- Complex hierarchical gaussian filter\n",
    "- Complex to real conversion\n",
    "- Observation noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mActivating\u001b[22m\u001b[39m environment at `C:\\Users\\s151781\\AppData\\Local\\Julia-1.3.1\\GN\\Project.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.activate(\"C:/Users/s151781/AppData/Local/Julia-1.3.1/GN/Project.toml\")\n",
    "using Revise\n",
    "using FFTW\n",
    "using Compat\n",
    "using WAV\n",
    "using DSP\n",
    "using Base64\n",
    "using ForneyLab\n",
    "using LinearAlgebra\n",
    "using ProgressMeter\n",
    "using PyPlot\n",
    "using GaussianMixtures\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../extensions/ComplexNormal.jl\")\n",
    "include(\"../extensions/ComplexHGF.jl\")\n",
    "include(\"../extensions/ComplexToReal.jl\")\n",
    "include(\"../functions/auxiliary/workflow.jl\") # for some workflow simplifications\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation parameters\n",
    "nr_samples = 200                     # number of samples\n",
    "nr_freqs = 5                         # number of frequencies\n",
    "nr_clusters = 3                      # number of clusters (needs to be larger than 2 (ForneyLab issue))\n",
    "fs = 1                               # sampling frequency\n",
    "\n",
    "Σ_ξ = 1e-4*Ic(nr_freqs)              # covariance matrix of ξ\n",
    "Σ_meas = 1e-10*Ic(2*nr_freqs)        # covariance matrix of measurement noise (over frequencies (real + imag) in this case)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sampling functions\n",
    "import Distributions: Normal, MvNormal, MixtureModel, Dirichlet\n",
    "\n",
    "# set means of ξ for the different clusters\n",
    "μ_ξ = vcat([collect(k:k:k*nr_freqs) for k = 1:nr_clusters])\n",
    "\n",
    "# create arrays over samples\n",
    "cluster_id = Array{Int64,1}(undef, nr_samples)\n",
    "ξ_samples = Array{Array{Float64,1},1}(undef, nr_samples)\n",
    "Xc_samples = Array{Array{Complex{Float64},1},1}(undef, nr_samples)\n",
    "Xr_samples = Array{Array{Float64,1},1}(undef, nr_samples)\n",
    "Y_samples = Array{Array{Float64,1},1}(undef, nr_samples)\n",
    "\n",
    "# generate samples independent from each other\n",
    "for n = 1:nr_samples\n",
    "     \n",
    "    # create arrays over frequencies\n",
    "    ξ_samples[n] = Array{Float64,1}(undef, nr_freqs)\n",
    "    Xc_samples[n] = Array{Complex{Float64},1}(undef, nr_freqs)\n",
    "    Xr_samples[n] = Array{Float64,1}(undef, 2*nr_freqs)\n",
    "    Y_samples[n] = Array{Float64,1}(undef, 2*nr_freqs)\n",
    "    \n",
    "    # randomly pick cluster to get means from \n",
    "    cluster_id[n] = rand(collect(1:nr_clusters))\n",
    "    μ_ξi = μ_ξ[cluster_id[n]]\n",
    "    \n",
    "    # calculate samples fro frequencies\n",
    "    for k = 1:nr_freqs\n",
    "        \n",
    "        # generate samples (log-power domain)\n",
    "        sample_ξ = rand(Normal(μ_ξi[k], sqrt(Σ_ξ[k,k])))\n",
    "        \n",
    "        # generate samples (complex frequency coefs)\n",
    "        sample_Xc = rand(Normal(0, sqrt(0.5*exp(sample_ξ)))) + 1im*rand(Normal(0, sqrt(0.5*exp(sample_ξ))))\n",
    "        \n",
    "        # generate samples (real frequency coefs)\n",
    "        sample_Xr = hcat(real.(sample_Xc), imag.(sample_Xc))\n",
    "        \n",
    "        # generate samples (noisy observations)\n",
    "        sample_Y = [rand(Normal(sample_Xr[1], sqrt(Σ_meas[2*k-1,2*k-1]))), rand(Normal(sample_Xr[2], sqrt(Σ_meas[2*k,2*k])))]\n",
    "\n",
    "        # save samples\n",
    "        ξ_samples[n][k] = sample_ξ\n",
    "        Xc_samples[n][k] = sample_Xc\n",
    "        Xr_samples[n][k] = sample_Xr[1]\n",
    "        Xr_samples[n][k+nr_freqs] = sample_Xr[2]\n",
    "        Y_samples[n][k] = sample_Y[1]\n",
    "        Y_samples[n][k+nr_freqs] = sample_Y[2]\n",
    "        \n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "# create time axis\n",
    "t = collect(1:nr_samples)/fs\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build factor graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create factor graph\n",
    "fg = FactorGraph()\n",
    "\n",
    "# create distionary for variables\n",
    "vars = Dict()\n",
    "\n",
    "# specify distribution over the selection variables\n",
    "@RV vars[:π] ~ ForneyLab.Dirichlet(placeholder(:α_π, dims=(nr_clusters,)))\n",
    "\n",
    "# create mixture components\n",
    "for k = 1:nr_clusters\n",
    "    \n",
    "    # specify distribution over precision matrix\n",
    "    @RV vars[pad(:w,k)] ~ Wishart(placeholder(pad(:V_w,k), dims=(nr_freqs,nr_freqs)), placeholder(pad(:nu_w,k)))\n",
    "    \n",
    "    # specify distribution over mean\n",
    "    @RV vars[pad(:m,k)] ~ GaussianMeanPrecision(placeholder(pad(:μ_m,k), dims=(nr_freqs,)), vars[pad(:w,k)])\n",
    "    \n",
    "end\n",
    "\n",
    "# create sample-dependent random variables\n",
    "for k = 1:nr_samples\n",
    "    \n",
    "    # specify distribution over selection variable\n",
    "    @RV vars[pad(:z,k)] ~ Categorical(vars[:π])\n",
    "    \n",
    "    # create gaussian mixture model\n",
    "    @RV vars[pad(:ξ,k)] ~ GaussianMixture(vars[pad(:z,k)], expand([[vars[pad(:m,ki)], vars[pad(:w,ki)]] for ki=1:nr_clusters])...)\n",
    "    \n",
    "    # log-power to complex fourier coefficients transform\n",
    "    @RV vars[pad(:Xc,k)] ~ ComplexHGF(vars[pad(:ξ,k)])\n",
    "\n",
    "    # complex fourier coefficients to real and imaginary parts concatenated\n",
    "    @RV vars[pad(:Xr,k)] ~ ComplexToReal(vars[pad(:Xc,k)])\n",
    "    \n",
    "    # observation model \n",
    "    @RV vars[pad(:Y,k)] ~ GaussianMeanVariance(vars[pad(:Xr,k)], Σ_meas)\n",
    "    \n",
    "    # observation\n",
    "    placeholder(vars[pad(:Y,k)], :Y, index=k, dims=(2*nr_freqs,))\n",
    "    \n",
    "end\n",
    "\n",
    "# draw graph\n",
    "# ForneyLab.draw(fg)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate inference algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify ids for the posterior factorization\n",
    "q_ids = vcat(:Π,\n",
    "              expand([[pad(:M,k), pad(:W,k)] for k=1:nr_clusters]),\n",
    "              :Z, :Xc, :Ξ)\n",
    "\n",
    "# specify posterior factorization\n",
    "q = PosteriorFactorization(vars[:π], \n",
    "                           expand([[vars[pad(:m,k)], vars[pad(:w,k)]] for k=1:nr_clusters])...,\n",
    "                           [vars[pad(:z,k)] for k=1:nr_samples],\n",
    "                           [vars[pad(:Xc,k)] for k=1:nr_samples],\n",
    "                           [vars[pad(:ξ,k)] for k=1:nr_samples],\n",
    "                           ids=q_ids)\n",
    "\n",
    "# generate the inference algorithm\n",
    "algo = variationalAlgorithm(q)\n",
    "\n",
    "# Generate source code\n",
    "source_code = algorithmSourceCode(algo)\n",
    "\n",
    "# Load algorithm\n",
    "eval(Meta.parse(source_code))\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate priors over means through K-means clustering and the EM-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iters               objv        objv-change | affected \n",
      "-------------------------------------------------------------\n",
      "      0       2.476037e+03\n",
      "      1       1.600574e+03      -8.754635e+02 |        3\n",
      "      2       1.593951e+03      -6.622835e+00 |        0\n",
      "      3       1.593951e+03       0.000000e+00 |        0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Initializing GMM, 3 Gaussians diag covariance 5 dimensions using 200 data points\n",
      "└ @ GaussianMixtures C:\\Users\\s151781\\.julia\\packages\\GaussianMixtures\\3jRIL\\src\\train.jl:78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-means converged with 3 iterations (objv = 1593.9507847108434)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: K-means with 200 data points using 3 iterations\n",
      "│ 11.1 data points per parameter\n",
      "└ @ GaussianMixtures C:\\Users\\s151781\\.julia\\packages\\GaussianMixtures\\3jRIL\\src\\train.jl:139\n"
     ]
    }
   ],
   "source": [
    "# reshape Y\n",
    "Yi = hcat(Y_samples...)\n",
    "\n",
    "# approximate with log-power\n",
    "Yi = collect(log.(abs2.(Yi[1:nr_freqs,:] + 1im*Yi[nr_freqs+1:end,:]))')\n",
    "\n",
    "# perform clustering\n",
    "g = GMM(nr_clusters, Yi, nIter=50, nInit=100, kind=:diag)\n",
    "em!(g, Yi)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data and marginals dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data dictionary\n",
    "data = Dict()\n",
    "\n",
    "# specify input data and measurement noise\n",
    "data[:Y] = Y_samples\n",
    "\n",
    "# specify priors over class probabilities\n",
    "data[:α_π] = 1.0*ones(nr_clusters)\n",
    "\n",
    "# specify priors over clusters\n",
    "for k = 1:nr_clusters\n",
    "    data[pad(:μ_m,k)] = g.μ[k,:]\n",
    "    data[pad(:nu_w,k)] = nr_freqs\n",
    "    data[pad(:V_w,k)] = diagm(1 ./g.Σ[k,:]) / nr_freqs\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create marginals dictionary\n",
    "marginals = Dict()\n",
    "\n",
    "# specify marginals over class probabilities\n",
    "marginals[:vars_π] = vague(ForneyLab.Dirichlet, nr_clusters)\n",
    "\n",
    "# specify marginals over clusters\n",
    "for k = 1:nr_clusters\n",
    "    marginals[pad(:vars_m,k)] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=data[pad(:μ_m,k)], w=data[pad(:V_w,k)]*data[pad(:nu_w,k)])\n",
    "    marginals[pad(:vars_w,k)] = ProbabilityDistribution(MatrixVariate, ForneyLab.Wishart, v=data[pad(:V_w,k)], nu=data[pad(:nu_w,k)])\n",
    "end\n",
    "\n",
    "# specify marginals over samples\n",
    "for k = 1:nr_samples\n",
    "    marginals[pad(:vars_z,k)] = vague(Categorical)\n",
    "    marginals[pad(:vars_Xc,k)] = ProbabilityDistribution(Multivariate, ComplexNormal, μ=zeros(nr_freqs) .+ 0.0im, Γ=1e10*Ic(nr_freqs).+0.0im, C=mat(0.0+0.0im));\n",
    "    marginals[pad(:vars_ξ,k)] = ProbabilityDistribution(Multivariate, GaussianMeanVariance, m=zeros(nr_freqs), v=Ic(nr_freqs))\n",
    "end\n",
    "; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:05:31\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# set number of iterations\n",
    "nr_its = 10\n",
    "\n",
    "# create progress bar\n",
    "p = Progress(nr_its)\n",
    "\n",
    "# perform iterations\n",
    "for i = 1:nr_its\n",
    "    \n",
    "    # perform updates\n",
    "    stepXc!(data, marginals)\n",
    "    stepΞ!(data, marginals)\n",
    "    stepZ!(data, marginals)\n",
    "    stepΠ!(data, marginals) \n",
    "    for k = 1:nr_clusters\n",
    "        getfield(Main, Symbol(\"stepM_\"*string(k,pad=2)*\"!\"))(data, marginals)\n",
    "        getfield(Main, Symbol(\"stepW_\"*string(k,pad=2)*\"!\"))(data, marginals)\n",
    "    end\n",
    "    \n",
    "    # update progress bar\n",
    "    next!(p)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze inferred cluster assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_inferred = [findmax(marginals[pad(:vars_z,k)].params[:p])[2] for k = 1:nr_samples];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Array{Int64,2}:\n",
       " 64   0   0\n",
       "  0  70   0\n",
       "  0   2  64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function confusionmatrix(k::Integer, gts::Array{Int64,1}, preds::Array{Int64,1})\n",
    "    # borrowed from MLBase\n",
    "    n = length(gts)\n",
    "    length(preds) == n || throw(DimensionMismatch(\"Inconsistent lengths.\"))\n",
    "    R = zeros(Int, k, k)\n",
    "    for i = 1:n\n",
    "        @inbounds g = gts[i]\n",
    "        @inbounds p = preds[i]\n",
    "        R[g, p] += 1\n",
    "    end\n",
    "    return R\n",
    "end\n",
    "\n",
    "confusionmatrix(nr_clusters, cluster_id .- minimum(cluster_id) .+ 1, z_inferred .- minimum(z_inferred) .+ 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×5 Array{Float64,2}:\n",
       " 0.047027  1.24658  2.50007   3.00019   4.59574\n",
       " 1.33687   3.50789  5.50818   7.15009   9.69943\n",
       " 2.66747   5.80304  8.4861   11.5997   14.4736 "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.μ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04876835551318326, 1.2448231055089947, 2.501001130462622, 3.0001092337285775, 4.609151413737056]\n",
      "[1.3402234069963332, 3.5186433259400465, 5.500616731084405, 7.1588516151403825, 9.716459313299525]\n",
      "[2.6822840279243287, 5.805194210205965, 8.50725161375487, 11.61623575331676, 14.46282083483107]\n"
     ]
    }
   ],
   "source": [
    "for k = 1:nr_clusters\n",
    "    println(ForneyLab.unsafeMean(marginals[pad(:vars_m,k)]))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
